[
  {
    "objectID": "content/01_journal/01_probability.html",
    "href": "content/01_journal/01_probability.html",
    "title": "Probability Theory",
    "section": "",
    "text": "# Assignment 1\n# Define the given values\nprobability_S &lt;- 0.3\nprobability_not_S &lt;- 0.7\nconditional_probability_T_given_S &lt;- 0.2\nconditional_probability_T_given_not_S &lt;- 0.6\nconditional_probability_not_T_given_S &lt;- 0.8\nconditional_probability_not_T_given_not_S &lt;- 0.4\n\n# Calculate the probabilities\nprobability_T_and_S &lt;- conditional_probability_T_given_S * probability_S\nprobability_T_and_not_s &lt;- conditional_probability_T_given_not_S * probability_not_S\nprobability_not_T_and_S &lt;- conditional_probability_not_T_given_S * probability_S\nprobability_not_T_and_not_S &lt;- conditional_probability_not_T_given_not_S * probability_not_S\ntotal_sum &lt;- probability_T_and_S + probability_T_and_not_s + probability_not_T_and_S + probability_not_T_and_not_S\n\n# Display the probabilities and the sum\ncat(\"P(T ∩ S):\",probability_T_and_S , \"\\n\")\n\n#&gt; P(T ∩ S): 0.06\n\ncat(\"P(T ∩ S'): \",probability_T_and_not_s, \"\\n\")\n\n#&gt; P(T ∩ S'):  0.42\n\ncat(\"P(T' ∩ S): \",probability_not_T_and_S, \"\\n\")\n\n#&gt; P(T' ∩ S):  0.24\n\ncat(\"P(T' ∩ S'): \",probability_not_T_and_not_S, \"\\n\\n\")\n\n#&gt; P(T' ∩ S'):  0.28\n\ncat(\"Sum of all four probabilities:\", total_sum, \"\\n\")\n\n#&gt; Sum of all four probabilities: 1\n\n\n\n# Assignment 2\n# Assuming you have the percentages\npercentage_all_three &lt;- 0.5\npercentage_at_least_two &lt;- 19.9\npercentage_only_one &lt;- 80.1\n\n# Display the percentages\ncat(\"Percentage of customers using all three devices:\", percentage_all_three, \"%\\n\")\n\n#&gt; Percentage of customers using all three devices: 0.5 %\n\ncat(\"Percentage of customers using at least two devices:\", percentage_at_least_two, \"%\\n\")\n\n#&gt; Percentage of customers using at least two devices: 19.9 %\n\ncat(\"Percentage of customers using only one device:\", percentage_only_one, \"%\\n\")\n\n#&gt; Percentage of customers using only one device: 80.1 %\n\n\n\n# Assignment 3\n# Given probabilities\nP_A &lt;- 0.04\nP_B_given_A &lt;- 0.97\nP_B_given_not_A &lt;- 0.01\n\n# Calculate complementary probability\nP_not_A &lt;- 1 - P_A\n\n# Calculate total probability of triggering an alarm\nP_B &lt;- P_B_given_A * P_A + P_B_given_not_A * P_not_A\n\n# Apply Bayes' theorem\nP_not_A_given_B &lt;- (P_B_given_not_A * P_not_A) / P_B\nP_A_given_B &lt;- (P_B_given_A * P_A) / P_B\n\n# Display the results\ncat(\"These results show that in case the alarm is triggered, there is a possibility of about\", P_not_A_given_B * 100, \"% that the product is flawless and a probability of about\", P_A_given_B * 100, \"% that the product is faulty.\\n\")\n\n#&gt; These results show that in case the alarm is triggered, there is a possibility of about 19.83471 % that the product is flawless and a probability of about 80.16529 % that the product is faulty."
  },
  {
    "objectID": "content/01_journal/01_probability.html#header-2",
    "href": "content/01_journal/01_probability.html#header-2",
    "title": "Probability Theory",
    "section": "2.1 Header 2",
    "text": "2.1 Header 2\n\nHeader 3\n\nHeader 4\n\nHeader 5\n\nHeader 6"
  },
  {
    "objectID": "content/01_journal/10_rdd.html",
    "href": "content/01_journal/10_rdd.html",
    "title": "Regression Discontinuity",
    "section": "",
    "text": "#1st part\n\ndata &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/coupon.rds\")\n\n# Define cut-off\nc0 &lt;- 60\n\nlibrary(rddensity)\nrddd &lt;- rddensity(data$days_since_last, c = c0)\nsummary(rddd)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       5000\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           estimated\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 60                Left of c           Right of c          \n#&gt; Number of obs         3854                1146                \n#&gt; Eff. Number of obs    1486                734                 \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           31.203              31.915              \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                1.1559              0.2477\n\n\n#&gt; Warning in summary.CJMrddensity(rddd): There are repeated observations. Point\n#&gt; estimates and standard errors have been adjusted. Use option massPoints=FALSE\n#&gt; to suppress this feature.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 0.500                      20      20    1.0000\n#&gt; 1.000                      31      35    0.7122\n#&gt; 1.500                      44      47    0.8341\n#&gt; 2.000                      70      68    0.9322\n#&gt; 2.500                      92      89    0.8819\n#&gt; 3.000                     110     105    0.7851\n#&gt; 3.500                     123     118    0.7967\n#&gt; 4.000                     135     129    0.7584\n#&gt; 4.500                     148     142    0.7691\n#&gt; 5.000                     164     159    0.8239\n\n\n\n# Specify your outcome variable (dependent variable)\noutcome_var &lt;- \"purchase_after\"\n\n# Specify your running variable (the variable used for the RDD)\nrunning_var &lt;- \"days_since_last\"\n\n# Specify the bandwidth\nbandwidth_original &lt;- 5  # Adjust this value based on your initial analysis\n\nlm_bw &lt;- lm(purchase_after ~ days_since_last, data)\nsummary(lm_bw)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_after ~ days_since_last, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -14.244  -3.620  -0.558   2.868  34.353 \n#&gt; \n#&gt; Coefficients:\n#&gt;                  Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)     12.353269   0.117865  104.81   &lt;2e-16 ***\n#&gt; days_since_last  0.053425   0.002281   23.42   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 5.331 on 4998 degrees of freedom\n#&gt; Multiple R-squared:  0.09889,    Adjusted R-squared:  0.09871 \n#&gt; F-statistic: 548.5 on 1 and 4998 DF,  p-value: &lt; 2.2e-16\n\nrddd &lt;- rddensity(data$purchase_after, h = bandwidth_original)\n\n# Print the results\nsummary(rddd)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       5000\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           mannual\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 0                 Left of c           Right of c          \n#&gt; Number of obs         1                   4999                \n#&gt; Eff. Number of obs    1                   66                  \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           5                   5                   \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                NA                  NA\n\n\n#&gt; Warning in summary.CJMrddensity(rddd): Bandwidth hl greater than the range of\n#&gt; the data.\n\n\n#&gt; Warning in summary.CJMrddensity(rddd): Bandwidth h may be too small.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 3.519                       1      20    0.0000\n#&gt; 3.684                       1      22    0.0000\n#&gt; 3.848                       1      23    0.0000\n#&gt; 4.013                       1      29    0.0000\n#&gt; 4.177                       1      36    0.0000\n#&gt; 4.342                       1      42    0.0000\n#&gt; 4.506                       1      49    0.0000\n#&gt; 4.671                       1      54    0.0000\n#&gt; 4.835                       1      59    0.0000\n#&gt; 5.000                       1      66    0.0000\n\n# half the bandwidth\nhalf_bandwidth_result &lt;- rddensity(data$purchase_after, h = bandwidth_original/2)\nsummary(half_bandwidth_result)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       5000\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           mannual\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 0                 Left of c           Right of c          \n#&gt; Number of obs         1                   4999                \n#&gt; Eff. Number of obs    1                   7                   \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           2.5                 2.5                 \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                NA                  NA\n\n\n#&gt; Warning in summary.CJMrddensity(half_bandwidth_result): Bandwidth hl greater\n#&gt; than the range of the data.\n\n\n#&gt; Warning in summary.CJMrddensity(half_bandwidth_result): Bandwidth h may be too\n#&gt; small.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 3.519                       1      20    0.0000\n\n#double the bandwidth\ndouble_bandwidth_result &lt;- rddensity(data$purchase_after, h = bandwidth_original * 2)\nsummary(double_bandwidth_result)\n\n#&gt; \n#&gt; Manipulation testing using local polynomial density estimation.\n#&gt; \n#&gt; Number of obs =       5000\n#&gt; Model =               unrestricted\n#&gt; Kernel =              triangular\n#&gt; BW method =           mannual\n#&gt; VCE method =          jackknife\n#&gt; \n#&gt; c = 0                 Left of c           Right of c          \n#&gt; Number of obs         1                   4999                \n#&gt; Eff. Number of obs    1                   1118                \n#&gt; Order est. (p)        2                   2                   \n#&gt; Order bias (q)        3                   3                   \n#&gt; BW est. (h)           10                  10                  \n#&gt; \n#&gt; Method                T                   P &gt; |T|             \n#&gt; Robust                NA                  NA\n\n\n#&gt; Warning in summary.CJMrddensity(double_bandwidth_result): Bandwidth hl greater\n#&gt; than the range of the data.\n\n\n#&gt; Warning in summary.CJMrddensity(double_bandwidth_result): Bandwidth h may be\n#&gt; too small.\n\n\n#&gt; \n#&gt; P-values of binomial tests (H0: p=0.5).\n#&gt; \n#&gt; Window Length / 2          &lt;c     &gt;=c    P&gt;|T|\n#&gt; 3.519                       1      20    0.0000\n#&gt; 4.239                       1      38    0.0000\n#&gt; 4.960                       1      66    0.0000\n#&gt; 5.680                       1      99    0.0000\n#&gt; 6.400                       1     176    0.0000\n#&gt; 7.120                       1     261    0.0000\n#&gt; 7.840                       1     419    0.0000\n#&gt; 8.560                       1     603    0.0000\n#&gt; 9.280                       1     836    0.0000\n#&gt; 10.000                      1    1118    0.0000\n\n\n\n#2nd part\n# Load necessary libraries and data\nlibrary(ggplot2)\nlibrary(foreign)  \n\nshipping_data &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/shipping.rds\")\n\n# Check the structure of your data\nstr(shipping_data)\n\n#&gt; tibble [6,666 × 1] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ purchase_amount: num [1:6666] 13.11 37.12 11.26 9.45 53.24 ...\n\n# Check the structure of your data\nstr(shipping_data)\n\n#&gt; tibble [6,666 × 1] (S3: tbl_df/tbl/data.frame)\n#&gt;  $ purchase_amount: num [1:6666] 13.11 37.12 11.26 9.45 53.24 ...\n\n# Create a histogram of purchase amounts\nggplot(shipping_data, aes(x = purchase_amount)) +\n  geom_histogram(binwidth = 5, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Purchase Amounts\",\n       x = \"Purchase Amount\",\n       y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe histogram above illustrates the distribution of purchase amounts from the dataset corresponding to a past campaign where free shipping was offered for purchases with a total amount exceeding 30€. To determine whether purchase_amount is a suitable running variable with a natural cut-off at 30€, we can observe the shape of the distribution. The histogram shows a noticeable change in frequency around the 30€ mark, suggesting a potential threshold effect. Values to the left of 30€ represent purchases that did not qualify for free shipping, while those to the right indicate purchases that met the criteria for free shipping. This natural separation aligns with the campaign’s conditions, making purchase_amount a plausible running variable for assessing the impact of the free shipping offer. In conclusion, based on the visual examination of the histogram, purchase_amount appears to be a promising running variable for studying the impact of the free shipping campaign, with a clear threshold effect at the 30€ mark."
  },
  {
    "objectID": "content/01_journal/08_did.html",
    "href": "content/01_journal/08_did.html",
    "title": "Difference-in-Differences",
    "section": "",
    "text": "#1\ndata &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/hospdd.rds\")\n# Load necessary libraries\nlibrary(dplyr)\n\n# Assuming 'data' is your data frame\n# Filter the data for all hospitals before and after treatment\nall_before &lt;- data %&gt;% filter(month == \"Before\") \nall_after &lt;- data %&gt;% filter(month == \"After\")\n\n# Filter the data for treated hospitals before and after treatment\ntreated_before &lt;- all_before %&gt;% filter(procedure == 1) \ntreated_after &lt;- all_after %&gt;% filter(procedure == 1)\n\n# Filter the data for control hospitals before and after treatment\ncontrol_before &lt;- all_before %&gt;% filter(procedure == 0) \ncontrol_after &lt;- all_after %&gt;% filter(procedure == 0)\n\n# Print the results\n# Compute the mean satisfaction for each group and time period\nmean_satisfaction_treated_before &lt;- mean(treated_before$satis, na.rm = TRUE)\nmean_satisfaction_treated_after &lt;- mean(treated_after$satis, na.rm = TRUE)\n\nmean_satisfaction_control_before &lt;- mean(control_before$satis, na.rm = TRUE)\nmean_satisfaction_control_after &lt;- mean(control_after$satis, na.rm = TRUE)\n\n# Print the results\ncat(\"Mean satisfaction for treated hospitals before treatment:\", mean_satisfaction_treated_before, \"\\n\")\n\n#&gt; Mean satisfaction for treated hospitals before treatment: NaN\n\ncat(\"Mean satisfaction for treated hospitals after treatment:\", mean_satisfaction_treated_after, \"\\n\")\n\n#&gt; Mean satisfaction for treated hospitals after treatment: NaN\n\ncat(\"Mean satisfaction for control hospitals before treatment:\", mean_satisfaction_control_before, \"\\n\")\n\n#&gt; Mean satisfaction for control hospitals before treatment: NaN\n\ncat(\"Mean satisfaction for control hospitals after treatment:\", mean_satisfaction_control_after, \"\\n\")\n\n#&gt; Mean satisfaction for control hospitals after treatment: NaN\n\n\n\n#2\n#Option 1: Month + Hospital\nmodel1 &lt;- lm(satis ~ procedure + month + hospital, data = data)\nsummary(model1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure + month + hospital, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.3126 -0.6548 -0.0933  0.5555  5.3347 \n#&gt; \n#&gt; Coefficients:\n#&gt;              Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  3.538024   0.031365 112.801  &lt; 2e-16 ***\n#&gt; procedure    0.886120   0.039143  22.638  &lt; 2e-16 ***\n#&gt; month       -0.004965   0.006392  -0.777 0.437378    \n#&gt; hospital    -0.003731   0.001043  -3.576 0.000351 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.9836 on 7364 degrees of freedom\n#&gt; Multiple R-squared:  0.1325, Adjusted R-squared:  0.1321 \n#&gt; F-statistic: 374.8 on 3 and 7364 DF,  p-value: &lt; 2.2e-16\n\n# Option 2: as.factor(Month) + as.factor(Hospital)\nmodel2 &lt;- lm(satis ~ procedure + as.factor(month) + as.factor(hospital), data = data)\nsummary(model2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satis ~ procedure + as.factor(month) + as.factor(hospital), \n#&gt;     data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -3.1880 -0.4644  0.0067  0.4539  4.2921 \n#&gt; \n#&gt; Coefficients:\n#&gt;                         Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)            3.1716566  0.0562207  56.414  &lt; 2e-16 ***\n#&gt; procedure              0.8479879  0.0342191  24.781  &lt; 2e-16 ***\n#&gt; as.factor(month)2     -0.0096077  0.0292119  -0.329 0.742244    \n#&gt; as.factor(month)3      0.0219686  0.0292119   0.752 0.452050    \n#&gt; as.factor(month)4     -0.0032839  0.0324936  -0.101 0.919504    \n#&gt; as.factor(month)5     -0.0094027  0.0324936  -0.289 0.772305    \n#&gt; as.factor(month)6     -0.0038375  0.0324936  -0.118 0.905990    \n#&gt; as.factor(month)7     -0.0111941  0.0324936  -0.345 0.730478    \n#&gt; as.factor(hospital)2   0.4085664  0.0772418   5.289 1.26e-07 ***\n#&gt; as.factor(hospital)3   0.5336248  0.0793384   6.726 1.88e-11 ***\n#&gt; as.factor(hospital)4   0.2275102  0.0739411   3.077 0.002099 ** \n#&gt; as.factor(hospital)5  -0.1453529  0.0739411  -1.966 0.049360 *  \n#&gt; as.factor(hospital)6   0.4478634  0.0739411   6.057 1.46e-09 ***\n#&gt; as.factor(hospital)7   1.4044164  0.0714559  19.654  &lt; 2e-16 ***\n#&gt; as.factor(hospital)8   0.0718758  0.0763186   0.942 0.346333    \n#&gt; as.factor(hospital)9  -1.5185150  0.0782447 -19.407  &lt; 2e-16 ***\n#&gt; as.factor(hospital)10  1.6828446  0.0772418  21.787  &lt; 2e-16 ***\n#&gt; as.factor(hospital)11  0.2209653  0.0763186   2.895 0.003799 ** \n#&gt; as.factor(hospital)12 -0.0953034  0.0782447  -1.218 0.223256    \n#&gt; as.factor(hospital)13  0.4955931  0.0754658   6.567 5.48e-11 ***\n#&gt; as.factor(hospital)14  0.2330426  0.0793384   2.937 0.003321 ** \n#&gt; as.factor(hospital)15 -0.1444935  0.0793384  -1.821 0.068613 .  \n#&gt; as.factor(hospital)16  1.4142680  0.0772418  18.310  &lt; 2e-16 ***\n#&gt; as.factor(hospital)17  0.4235429  0.0805362   5.259 1.49e-07 ***\n#&gt; as.factor(hospital)18  0.1532761  0.0938164   1.634 0.102346    \n#&gt; as.factor(hospital)19 -0.7453017  0.0811623  -9.183  &lt; 2e-16 ***\n#&gt; as.factor(hospital)20  0.0473874  0.0791140   0.599 0.549207    \n#&gt; as.factor(hospital)21  1.1943370  0.0836232  14.282  &lt; 2e-16 ***\n#&gt; as.factor(hospital)22  0.7993153  0.0823336   9.708  &lt; 2e-16 ***\n#&gt; as.factor(hospital)23  0.7017202  0.0811623   8.646  &lt; 2e-16 ***\n#&gt; as.factor(hospital)24 -0.3081260  0.0866402  -3.556 0.000378 ***\n#&gt; as.factor(hospital)25  0.6464736  0.0927258   6.972 3.40e-12 ***\n#&gt; as.factor(hospital)26  0.2142471  0.0791140   2.708 0.006783 ** \n#&gt; as.factor(hospital)27 -0.3986544  0.0766106  -5.204 2.01e-07 ***\n#&gt; as.factor(hospital)28  0.7119953  0.0836232   8.514  &lt; 2e-16 ***\n#&gt; as.factor(hospital)29  0.2485512  0.0800935   3.103 0.001921 ** \n#&gt; as.factor(hospital)30 -0.1679220  0.0953638  -1.761 0.078304 .  \n#&gt; as.factor(hospital)31  0.5120848  0.0791140   6.473 1.02e-10 ***\n#&gt; as.factor(hospital)32 -0.3233456  0.0800935  -4.037 5.47e-05 ***\n#&gt; as.factor(hospital)33 -0.4539752  0.0791140  -5.738 9.95e-09 ***\n#&gt; as.factor(hospital)34 -0.0004123  0.0746054  -0.006 0.995590    \n#&gt; as.factor(hospital)35  0.3541110  0.0766106   4.622 3.86e-06 ***\n#&gt; as.factor(hospital)36  2.1381425  0.0773811  27.631  &lt; 2e-16 ***\n#&gt; as.factor(hospital)37  0.1404036  0.0927258   1.514 0.130023    \n#&gt; as.factor(hospital)38 -0.0868060  0.0782129  -1.110 0.267093    \n#&gt; as.factor(hospital)39 -0.0234969  0.0823336  -0.285 0.775356    \n#&gt; as.factor(hospital)40  1.1215331  0.0782129  14.339  &lt; 2e-16 ***\n#&gt; as.factor(hospital)41 -0.1497346  0.0766106  -1.954 0.050681 .  \n#&gt; as.factor(hospital)42  0.8811369  0.0850508  10.360  &lt; 2e-16 ***\n#&gt; as.factor(hospital)43 -0.7724325  0.0811623  -9.517  &lt; 2e-16 ***\n#&gt; as.factor(hospital)44  0.0344120  0.0904337   0.381 0.703569    \n#&gt; as.factor(hospital)45 -0.2137495  0.0766106  -2.790 0.005283 ** \n#&gt; as.factor(hospital)46  0.0784915  0.0823336   0.953 0.340452    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 0.7238 on 7315 degrees of freedom\n#&gt; Multiple R-squared:  0.5333, Adjusted R-squared:  0.5299 \n#&gt; F-statistic: 160.7 on 52 and 7315 DF,  p-value: &lt; 2.2e-16\n\n\nIn the analysis,considered two different specifications for the regression model, each incorporating group and time fixed effects. The first specification (Model 1) used numeric representations for months and hospitals (month + hospital), treating them as continuous variables. The second specification (Model 2) utilized categorical representations for months and hospitals (as.factor(month) + as.factor(hospital)), allowing for separate intercepts for each month and hospital category. Comparison: Model 2 has a higher R-squared value, suggesting that it explains a larger proportion of the variance in satisfaction compared to Model 1. Model 2 includes fixed effects for individual months and hospitals, providing more detailed insights into the impact of each specific month and hospital on satisfaction"
  },
  {
    "objectID": "content/01_journal/06_rct.html",
    "href": "content/01_journal/06_rct.html",
    "title": "Randomized Controlled Trials",
    "section": "",
    "text": "#1\n\nlibrary(dplyr)\n\n#&gt; Warning: package 'dplyr' was built under R version 4.3.2\n\n\n#&gt; \n#&gt; Attaching package: 'dplyr'\n\n\n#&gt; The following objects are masked from 'package:stats':\n#&gt; \n#&gt;     filter, lag\n\n\n#&gt; The following objects are masked from 'package:base':\n#&gt; \n#&gt;     intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n#&gt; Warning: package 'ggplot2' was built under R version 4.3.2\n\ndata &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/abtest_online.rds\")\n\ntreatment_data &lt;- subset(data, chatbot == 1)\ncontrol_data &lt;- subset(data, chatbot == 0)\n\n# Convert 'previous_visits' to numeric if it's not already\ndata &lt;- data %&gt;%\n  mutate(previous_visits = as.numeric(previous_visit))\n\n# Visualize covariate distributions\n# Using ggplot2 for a more flexible and customizable approach\nggplot(data, aes(x = previous_visit)) +\n  geom_histogram(binwidth = 1, fill = \"lightblue\", color = \"black\") +\n  facet_wrap(~ chatbot, scales = \"free\") +\n  labs(title = \"Distribution of Previous Visits by Group\", x = \"Previous Visits\")\n\n\n\n\n\n\n\n# Similar plot for 'mobile_device' as a bar plot\nggplot(data, aes(x = factor(mobile_device), fill = factor(mobile_device))) +\n  geom_bar() +\n  facet_wrap(~ chatbot) +\n  labs(title = \"Distribution of Mobile Device by Group\", x = \"Mobile Device\", y = \"Count\")\n\n\n\n\n\n\n\n\n\n#2\nmodel &lt;- lm(purchase_amount ~ chatbot, data = data)\nsummary(model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -16.702 -14.478  -9.626  13.922  64.648 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  16.7017     0.8374  19.944  &lt; 2e-16 ***\n#&gt; chatbotTRUE  -7.0756     1.1796  -5.998 2.79e-09 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.65 on 998 degrees of freedom\n#&gt; Multiple R-squared:  0.0348, Adjusted R-squared:  0.03383 \n#&gt; F-statistic: 35.98 on 1 and 998 DF,  p-value: 2.787e-09\n\n\n\n#3\n\nmodel_interaction &lt;- lm(purchase_amount ~ chatbot * mobile_device, data = data)\n\n\n# Print the summary of the interaction model\nsummary(model_interaction)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = purchase_amount ~ chatbot * mobile_device, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -16.98 -14.54  -9.95  14.13  65.24 \n#&gt; \n#&gt; Coefficients:\n#&gt;                               Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)                    16.9797     1.0152  16.725   &lt;2e-16 ***\n#&gt; chatbotTRUE                    -7.0301     1.4284  -4.922    1e-06 ***\n#&gt; mobile_deviceTRUE              -0.8727     1.7987  -0.485    0.628    \n#&gt; chatbotTRUE:mobile_deviceTRUE  -0.1526     2.5369  -0.060    0.952    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 18.66 on 996 degrees of freedom\n#&gt; Multiple R-squared:  0.03534,    Adjusted R-squared:  0.03244 \n#&gt; F-statistic: 12.16 on 3 and 996 DF,  p-value: 8.034e-08\n\n# Extract coefficients\ncoef_interaction &lt;- coef(model_interaction)\n\nprint(coef_interaction)\n\n#&gt;                   (Intercept)                   chatbotTRUE \n#&gt;                    16.9796632                    -7.0301039 \n#&gt;             mobile_deviceTRUE chatbotTRUE:mobile_deviceTRUE \n#&gt;                    -0.8726539                    -0.1525592\n\n# CATE for mobile users\nCATE_mobile &lt;- coef_interaction[\"chatbotTRUE\"] + coef_interaction[\"chatbotTRUE:mobile_deviceTRUE\"]\n\n# Print the CATE for mobile users\ncat(\"CATE for Mobile Users:\", CATE_mobile, \"\\n\")\n\n#&gt; CATE for Mobile Users: -7.182663\n\n\n\n#4\nlogistic_model &lt;- glm(purchase ~ chatbot, family = binomial(link = 'logit'), data = data)\nsummary(logistic_model)\n\n#&gt; \n#&gt; Call:\n#&gt; glm(formula = purchase ~ chatbot, family = binomial(link = \"logit\"), \n#&gt;     data = data)\n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    \n#&gt; (Intercept) -0.01613    0.08981  -0.180    0.857    \n#&gt; chatbotTRUE -0.98939    0.13484  -7.337 2.18e-13 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; (Dispersion parameter for binomial family taken to be 1)\n#&gt; \n#&gt;     Null deviance: 1329.1  on 999  degrees of freedom\n#&gt; Residual deviance: 1273.3  on 998  degrees of freedom\n#&gt; AIC: 1277.3\n#&gt; \n#&gt; Number of Fisher Scoring iterations: 4\n\n# Extract the coefficient for chatbot\ncoef_chatbot &lt;- coef(logistic_model)[\"chatbotTRUE\"]\n\nodds_ratio_chatbot &lt;- exp(coef_chatbot)\n\n# Print the results\ncat(\"Odds Ratio for Chatbot:\", odds_ratio_chatbot, \"\\n\")\n\n#&gt; Odds Ratio for Chatbot: 0.3718025\n\ncat(\"Coefficient for chatbot:\", coef_chatbot, \"\\n\")\n\n#&gt; Coefficient for chatbot: -0.9893925"
  },
  {
    "objectID": "content/01_journal/04_causality.html",
    "href": "content/01_journal/04_causality.html",
    "title": "Causality",
    "section": "",
    "text": "[Graph ]\n\nknitr::include_graphics(\"D:/Causal DS Assignment/cdsba-aneeshaanjali/images/chart.png\")\n\n\n\n\n\n\n\n# Install and load necessary packages\nlibrary(ggplot2)\n\n# Create random data for a spurious correlation\nset.seed(123)\ndata &lt;- data.frame(\n  crude_oil_imports = rnorm(100, mean = 62, sd = 40.54),\n  train_collisions = rnorm(100, mean = 64.909, sd = 12.26)\n)\n\n# Add a color variable to distinguish between the two variables\ndata$variable &lt;- rep(c(\"crude_oil_imports\", \"train_collisions\"), each = 50)\n# Create a scatter plot\nggplot(data, aes(x = crude_oil_imports, y = train_collisions, color = variable)) +\n  geom_point() +\n  ggtitle(\"Spurious Correlation\") +\n  xlab(\"US crude oil imports from Norway\") +\n  ylab(\"Drivers killed in collision with railway train\") +\n  scale_color_manual(values = c(\"crude_oil_imports\" = \"blue\", \"train_collisions\" = \"red\"))"
  },
  {
    "objectID": "content/01_journal/02_statistics.html",
    "href": "content/01_journal/02_statistics.html",
    "title": "Statistical Concepts",
    "section": "",
    "text": "random_vars &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/random_vars.rds\")\n\n# 1\n\n# Expected value (mean) for each variable\nexpected_values &lt;- sapply(random_vars, mean)\n\n# Variance for each variable\nvariances &lt;- sapply(random_vars, var)\n\n# Standard deviation for each variable\nstandard_deviations &lt;- sapply(random_vars, sd)\n\n# Display the results\nresults &lt;- data.frame(\n  Variable = names(random_vars),\n  Expected_Value = expected_values,\n  Variance = variances,\n  Standard_Deviation = standard_deviations\n)\n\nresults\n\n\n\n  \n\n\n\n\nComparing standard deviations is not always appropriate, especially when variables have different measurement units or represent fundamentally different characteristics. Additionally, standard deviations should be interpreted in conjunction with other statistical measures and the specific goals of the analysis.\n\n\n#3\n\n# Covariance between two variables\ncovariance_value &lt;- cov(random_vars$age, random_vars$income)\n\n# Correlation between two variables\ncorrelation_value &lt;- cor(random_vars$age, random_vars$income)\n\n# Display the results\nrelationship_results &lt;- data.frame(\n  Variable1 = \"age\",\n  Variable2 = \"income\",\n  Covariance = covariance_value,\n  Correlation = correlation_value\n)\n\nrelationship_results\n\n\n\n  \n\n\n\n\nThe correlation is generally easier to interpret compared to covariance, as it is a standardized measure that ranges from -1 to 1.Here the measure of correlation is 0.5479432, which suggests a moderate positive linear relationship. A positive correlation implies that as one variable increases, the other tends to increase as well. The magnitude of 0.5479432 indicates a moderate strength of the relationship. The closer the correlation coefficient is to 1, the stronger the positive linear relationship.\n\n\n#5\n\n# Compute conditional expected value for age &lt;= 18\nconditional_expected_value_age_less_than_18 &lt;- mean(random_vars$income[random_vars$age &lt;= 18])\n\n# Compute conditional expected value for age in [18, 65)\nconditional_expected_value_age_18_to_65 &lt;- mean(random_vars$income[random_vars$age &gt;= 18 & random_vars$age &lt; 65])\n\n# Compute conditional expected value for age &gt;= 65\nconditional_expected_value_age_greater_than_65 &lt;- mean(random_vars$income[random_vars$age &gt;= 65])\n\n# Display the results\nconditional_expected_values &lt;- data.frame(\n  Age_Group = c(\"Age &lt;= 18\", \"Age ∈ [18, 65)\", \"Age &gt;= 65\"),\n  Conditional_Expected_Value = c(\n    conditional_expected_value_age_less_than_18,\n    conditional_expected_value_age_18_to_65,\n    conditional_expected_value_age_greater_than_65\n  )\n)\n\nconditional_expected_values"
  },
  {
    "objectID": "content/01_journal/03_regression.html",
    "href": "content/01_journal/03_regression.html",
    "title": "Regression and Statistical Inference",
    "section": "",
    "text": "#1\ndata &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/car_prices.rds\")\n# Assuming your data is stored in a variable named 'data'\ndata_dimensions &lt;- dim(data)\n\n# Printing the number of rows and columns\nprint(paste(\"Number of rows:\", data_dimensions[1]))\n\n#&gt; [1] \"Number of rows: 181\"\n\nprint(paste(\"Number of columns:\", data_dimensions[2]))\n\n#&gt; [1] \"Number of columns: 22\"\n\n\n\n#2\n# Use str() to get the structure of the data\nstr(data)\n\n#&gt; Classes 'tbl_df', 'tbl' and 'data.frame':    181 obs. of  22 variables:\n#&gt;  $ aspiration      : chr  \"std\" \"std\" \"std\" \"std\" ...\n#&gt;  $ doornumber      : chr  \"two\" \"two\" \"two\" \"four\" ...\n#&gt;  $ carbody         : chr  \"convertible\" \"convertible\" \"hatchback\" \"sedan\" ...\n#&gt;  $ drivewheel      : chr  \"rwd\" \"rwd\" \"rwd\" \"fwd\" ...\n#&gt;  $ enginelocation  : chr  \"front\" \"front\" \"front\" \"front\" ...\n#&gt;  $ wheelbase       : num  88.6 88.6 94.5 99.8 99.4 ...\n#&gt;  $ carlength       : num  169 169 171 177 177 ...\n#&gt;  $ carwidth        : num  64.1 64.1 65.5 66.2 66.4 66.3 71.4 71.4 71.4 67.9 ...\n#&gt;  $ carheight       : num  48.8 48.8 52.4 54.3 54.3 53.1 55.7 55.7 55.9 52 ...\n#&gt;  $ curbweight      : num  2548 2548 2823 2337 2824 ...\n#&gt;  $ enginetype      : chr  \"dohc\" \"dohc\" \"ohcv\" \"ohc\" ...\n#&gt;  $ cylindernumber  : chr  \"four\" \"four\" \"six\" \"four\" ...\n#&gt;  $ enginesize      : num  130 130 152 109 136 136 136 136 131 131 ...\n#&gt;  $ fuelsystem      : chr  \"mpfi\" \"mpfi\" \"mpfi\" \"mpfi\" ...\n#&gt;  $ boreratio       : num  3.47 3.47 2.68 3.19 3.19 3.19 3.19 3.19 3.13 3.13 ...\n#&gt;  $ stroke          : num  2.68 2.68 3.47 3.4 3.4 3.4 3.4 3.4 3.4 3.4 ...\n#&gt;  $ compressionratio: num  9 9 9 10 8 8.5 8.5 8.5 8.3 7 ...\n#&gt;  $ horsepower      : num  111 111 154 102 115 110 110 110 140 160 ...\n#&gt;  $ peakrpm         : num  5000 5000 5000 5500 5500 5500 5500 5500 5500 5500 ...\n#&gt;  $ citympg         : num  21 21 19 24 18 19 19 19 17 16 ...\n#&gt;  $ highwaympg      : num  27 27 26 30 22 25 25 25 20 22 ...\n#&gt;  $ price           : num  13495 16500 16500 13950 17450 ...\n\n# Use summary() for a summary of the data\nsummary(data)\n\n#&gt;   aspiration         doornumber          carbody           drivewheel       \n#&gt;  Length:181         Length:181         Length:181         Length:181        \n#&gt;  Class :character   Class :character   Class :character   Class :character  \n#&gt;  Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;                                                                             \n#&gt;  enginelocation       wheelbase        carlength        carwidth    \n#&gt;  Length:181         Min.   : 86.60   Min.   :141.1   Min.   :60.30  \n#&gt;  Class :character   1st Qu.: 94.50   1st Qu.:166.3   1st Qu.:64.00  \n#&gt;  Mode  :character   Median : 96.50   Median :173.0   Median :65.40  \n#&gt;                     Mean   : 98.21   Mean   :173.3   Mean   :65.74  \n#&gt;                     3rd Qu.:100.40   3rd Qu.:180.2   3rd Qu.:66.50  \n#&gt;                     Max.   :120.90   Max.   :208.1   Max.   :72.30  \n#&gt;    carheight       curbweight    enginetype        cylindernumber    \n#&gt;  Min.   :47.80   Min.   :1488   Length:181         Length:181        \n#&gt;  1st Qu.:52.00   1st Qu.:2122   Class :character   Class :character  \n#&gt;  Median :53.70   Median :2410   Mode  :character   Mode  :character  \n#&gt;  Mean   :53.58   Mean   :2521                                        \n#&gt;  3rd Qu.:55.50   3rd Qu.:2910                                        \n#&gt;  Max.   :59.80   Max.   :4066                                        \n#&gt;    enginesize     fuelsystem          boreratio         stroke    \n#&gt;  Min.   : 61.0   Length:181         Min.   :2.540   Min.   :2.07  \n#&gt;  1st Qu.: 98.0   Class :character   1st Qu.:3.150   1st Qu.:3.08  \n#&gt;  Median :120.0   Mode  :character   Median :3.310   Median :3.23  \n#&gt;  Mean   :127.1                      Mean   :3.325   Mean   :3.23  \n#&gt;  3rd Qu.:141.0                      3rd Qu.:3.590   3rd Qu.:3.40  \n#&gt;  Max.   :326.0                      Max.   :3.940   Max.   :4.17  \n#&gt;  compressionratio   horsepower       peakrpm        citympg     \n#&gt;  Min.   : 7.000   Min.   : 48.0   Min.   :4200   Min.   :13.00  \n#&gt;  1st Qu.: 8.500   1st Qu.: 70.0   1st Qu.:4800   1st Qu.:19.00  \n#&gt;  Median : 9.000   Median : 95.0   Median :5200   Median :24.00  \n#&gt;  Mean   : 8.848   Mean   :106.2   Mean   :5182   Mean   :24.85  \n#&gt;  3rd Qu.: 9.400   3rd Qu.:116.0   3rd Qu.:5500   3rd Qu.:30.00  \n#&gt;  Max.   :11.500   Max.   :288.0   Max.   :6600   Max.   :49.00  \n#&gt;    highwaympg        price      \n#&gt;  Min.   :16.00   Min.   : 5118  \n#&gt;  1st Qu.:25.00   1st Qu.: 7609  \n#&gt;  Median :30.00   Median : 9980  \n#&gt;  Mean   :30.48   Mean   :12999  \n#&gt;  3rd Qu.:34.00   3rd Qu.:16430  \n#&gt;  Max.   :54.00   Max.   :45400\n\n# Use head() to display the first few rows of the data\nhead(data)\n\n\n\n  \n\n\n\n\n#3\n# Include all potential regressors\nlm_all &lt;- lm(price ~ ., data=data)\nsummary(lm_all)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ ., data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n#Let’s build a second regression model, where we only include variables that were statistically significant in the previous model.\n\n# Include only significant regressors\nlm_imp &lt;- lm(price ~ enginetype + cylindernumber + enginesize + stroke + peakrpm, data = data)\nsummary(lm_imp)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ enginetype + cylindernumber + enginesize + \n#&gt;     stroke + peakrpm, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -6032.7 -1231.6  -157.4  1163.4  8091.3 \n#&gt; \n#&gt; Coefficients:\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -3.803e+03  4.584e+03  -0.830 0.407877    \n#&gt; enginetypedohcv      -5.351e+03  3.247e+03  -1.648 0.101253    \n#&gt; enginetypel           4.275e+03  1.371e+03   3.117 0.002150 ** \n#&gt; enginetypeohc         3.508e+03  8.723e+02   4.022 8.74e-05 ***\n#&gt; enginetypeohcf        7.758e+02  1.117e+03   0.695 0.488171    \n#&gt; enginetypeohcv       -6.654e+03  1.249e+03  -5.327 3.19e-07 ***\n#&gt; cylindernumberfive   -6.220e+03  2.538e+03  -2.451 0.015291 *  \n#&gt; cylindernumberfour   -9.089e+03  2.491e+03  -3.649 0.000352 ***\n#&gt; cylindernumbersix    -5.299e+03  1.863e+03  -2.844 0.005015 ** \n#&gt; cylindernumberthree  -5.904e+03  4.110e+03  -1.437 0.152688    \n#&gt; cylindernumbertwelve -1.821e+04  3.001e+03  -6.070 8.34e-09 ***\n#&gt; enginesize            1.990e+02  1.091e+01  18.242  &lt; 2e-16 ***\n#&gt; stroke               -6.225e+03  8.397e+02  -7.414 5.86e-12 ***\n#&gt; peakrpm               3.393e+00  4.888e-01   6.941 8.21e-11 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2559 on 167 degrees of freedom\n#&gt; Multiple R-squared:  0.9067, Adjusted R-squared:  0.8994 \n#&gt; F-statistic: 124.8 on 13 and 167 DF,  p-value: &lt; 2.2e-16\n\n\n\n#4.1\n# Assuming 'enginetype' is a categorical variable\nstr(data$enginetype)\n\n#&gt;  chr [1:181] \"dohc\" \"dohc\" \"ohcv\" \"ohc\" \"ohc\" \"ohc\" \"ohc\" \"ohc\" \"ohc\" \"ohc\" ...\n\n# Unique values it can take on\nunique_values &lt;- unique(data$enginetype)\nprint(unique_values)\n\n#&gt; [1] \"dohc\"  \"ohcv\"  \"ohc\"   \"l\"     \"ohcf\"  \"dohcv\"\n\n\n\n#4.2 & 4.3\n# Fit a linear regression model with 'enginetype' as the only predictor\nmodel_enginetype &lt;- lm(price ~ enginetype, data =data)\nsummary(model_enginetype)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ enginetype, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt; -11599  -4237  -2171   1872  30223 \n#&gt; \n#&gt; Coefficients:\n#&gt;                 Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)        18116       2031   8.919 6.15e-16 ***\n#&gt; enginetypedohcv    13284       7324   1.814  0.07142 .  \n#&gt; enginetypel        -4324       3346  -1.292  0.19802    \n#&gt; enginetypeohc      -7025       2121  -3.312  0.00112 ** \n#&gt; enginetypeohcf     -4378       2725  -1.606  0.10999    \n#&gt; enginetypeohcv      6982       2817   2.479  0.01414 *  \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7037 on 175 degrees of freedom\n#&gt; Multiple R-squared:  0.2605, Adjusted R-squared:  0.2394 \n#&gt; F-statistic: 12.33 on 5 and 175 DF,  p-value: 2.981e-10\n\n\nWhen compared to the reference level, the ‘enginetypeohc’ and ‘enginetypeohcv’ categories have statistically significant effects on the price. The other categories (‘enginetypedohcv,’ ‘enginetypel,’ and ‘enginetypeohcf’) do not have statistically significant effects based on the p-values.  enginetypeohc: The estimated decrease in price for cars with ‘enginetypeohc’ compared to the reference level is $7,025. The p-value (0.00112) is less than 0.05, so the effect is statistically significant at the 0.05 significance level.  enginetypeohcv: The estimated increase in price for cars with ‘enginetypeohcv’ compared to the reference level is $6,982. The p-value (0.01414) is less than 0.05, so the effect is statistically significant at the 0.05 significance level.  Changing the value of ‘enginetype’ involves comparing the effect of different engine types on the predicted price\n\n#5\n\nlibrary(dplyr)\n\n# Add a new variable 'seat_heating' with value TRUE for all observations\nnew_df &lt;- data %&gt;% mutate(seat_heating = TRUE)\n\n# Run a regression with the new variable\nmodel_with_seat_heating &lt;- lm(price ~ . + seat_heating, data = new_df)\n\n# Print the summary of the linear regression model\nsummary(model_with_seat_heating)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = price ~ . + seat_heating, data = new_df)\n#&gt; \n#&gt; Residuals:\n#&gt;    Min     1Q Median     3Q    Max \n#&gt;  -5662  -1120      0    798   9040 \n#&gt; \n#&gt; Coefficients: (1 not defined because of singularities)\n#&gt;                        Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)          -36269.965  15460.866  -2.346 0.020354 *  \n#&gt; aspirationturbo        1846.206   1041.391   1.773 0.078386 .  \n#&gt; doornumbertwo           242.523    571.929   0.424 0.672172    \n#&gt; carbodyhardtop        -3691.743   1424.825  -2.591 0.010561 *  \n#&gt; carbodyhatchback      -3344.335   1238.359  -2.701 0.007757 ** \n#&gt; carbodysedan          -2292.820   1356.014  -1.691 0.093043 .  \n#&gt; carbodywagon          -3427.921   1490.285  -2.300 0.022885 *  \n#&gt; drivewheelfwd          -504.564   1076.623  -0.469 0.640030    \n#&gt; drivewheelrwd           -15.446   1268.070  -0.012 0.990299    \n#&gt; enginelocationrear     6643.492   2572.275   2.583 0.010806 *  \n#&gt; wheelbase               -30.197     92.776  -0.325 0.745294    \n#&gt; carlength               -29.740     51.672  -0.576 0.565824    \n#&gt; carwidth                731.819    244.533   2.993 0.003258 ** \n#&gt; carheight               123.195    134.607   0.915 0.361617    \n#&gt; curbweight                2.612      1.781   1.467 0.144706    \n#&gt; enginetypedohcv       -8541.957   4749.685  -1.798 0.074219 .  \n#&gt; enginetypel             978.748   1786.384   0.548 0.584619    \n#&gt; enginetypeohc          3345.252    933.001   3.585 0.000461 ***\n#&gt; enginetypeohcf          972.919   1625.631   0.598 0.550462    \n#&gt; enginetypeohcv        -6222.322   1236.415  -5.033 1.43e-06 ***\n#&gt; cylindernumberfive   -11724.540   3019.192  -3.883 0.000157 ***\n#&gt; cylindernumberfour   -11549.326   3177.177  -3.635 0.000387 ***\n#&gt; cylindernumbersix     -7151.398   2247.230  -3.182 0.001793 ** \n#&gt; cylindernumberthree   -4318.929   4688.833  -0.921 0.358545    \n#&gt; cylindernumbertwelve -11122.209   4196.494  -2.650 0.008946 ** \n#&gt; enginesize              125.934     26.541   4.745 5.00e-06 ***\n#&gt; fuelsystem2bbl          177.136    883.615   0.200 0.841400    \n#&gt; fuelsystemmfi         -3041.018   2576.996  -1.180 0.239934    \n#&gt; fuelsystemmpfi          359.278   1001.529   0.359 0.720326    \n#&gt; fuelsystemspdi        -2543.890   1363.546  -1.866 0.064140 .  \n#&gt; fuelsystemspfi          514.766   2499.229   0.206 0.837107    \n#&gt; boreratio             -1306.740   1642.221  -0.796 0.427516    \n#&gt; stroke                -4527.137    922.732  -4.906 2.49e-06 ***\n#&gt; compressionratio       -737.901    555.960  -1.327 0.186539    \n#&gt; horsepower               10.293     22.709   0.453 0.651035    \n#&gt; peakrpm                   2.526      0.634   3.983 0.000108 ***\n#&gt; citympg                 -90.352    166.647  -0.542 0.588538    \n#&gt; highwaympg              154.858    167.148   0.926 0.355761    \n#&gt; seat_heatingTRUE             NA         NA      NA       NA    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2189 on 143 degrees of freedom\n#&gt; Multiple R-squared:  0.9415, Adjusted R-squared:  0.9264 \n#&gt; F-statistic: 62.21 on 37 and 143 DF,  p-value: &lt; 2.2e-16\n\n\nPerfect Collinearity: If the new variable has the same value for all observations (in this case, TRUE for all), it will lead to perfect collinearity. Perfect collinearity occurs when one variable can be exactly predicted from another variable or a combination of other variables in the model. In such cases, the regression model cannot estimate the coefficients separately, resulting in NA coefficients.  Perfect Prediction: If the new variable is perfectly predictive of the dependent variable, the regression model may not be able to estimate the coefficients due to perfect prediction. This can occur when there is no variability in the dependent variable within each level of the new variable."
  },
  {
    "objectID": "content/01_journal/05_dag.html",
    "href": "content/01_journal/05_dag.html",
    "title": "Directed Acyclic Graphs",
    "section": "",
    "text": "#1\n# Load packages\nlibrary(dagitty)\nlibrary(ggdag)\n\n# create DAG from dagitty\ndag_model &lt;- 'dag {\nbb=\"0,0,1,1\"\nD [exposure,pos=\"0.075,0.4\"]\nY [outcome,pos=\"0.4,0.4\"]\nL [pos=\"0.2,0.2\"]\nS [pos=\"0.3,0.5\"]\nD -&gt; Y\nD -&gt; L\nS -&gt; D\nS -&gt; Y\nL -&gt; S\n}\n'\n\n# draw DAG\nggdag(dag_model) +\n  theme_dag() + # custom theme, can be left out\n  geom_dag_edges(edge_color = \"black\")\n\n\n\n\n\n\n\n\nD represents the treatment variable (having parking spots), Y represents the outcome variable (sales), L represents the location, and S represents the store.\n\ndata &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/customer_sat.rds\")\n\n#2.1\n#\nmodel1 &lt;- lm(satisfaction ~ follow_ups, data = data)\nsummary(model1)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -12.412  -5.257   1.733   4.506  12.588 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  78.8860     4.2717  18.467 1.04e-10 ***\n#&gt; follow_ups   -3.3093     0.6618  -5.001 0.000243 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 7.923 on 13 degrees of freedom\n#&gt; Multiple R-squared:  0.658,  Adjusted R-squared:  0.6316 \n#&gt; F-statistic: 25.01 on 1 and 13 DF,  p-value: 0.0002427\n\n\n\n#2.2\n# Assuming 'subscription' is another column in your dataset\nmodel2 &lt;- lm(satisfaction ~ follow_ups + subscription, data = data)\nsummary(model2)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = satisfaction ~ follow_ups + subscription, data = data)\n#&gt; \n#&gt; Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -4.3222 -2.1972  0.3167  2.2667  3.9944 \n#&gt; \n#&gt; Coefficients:\n#&gt;                      Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)           26.7667     6.6804   4.007  0.00206 ** \n#&gt; follow_ups             2.1944     0.7795   2.815  0.01682 *  \n#&gt; subscriptionPremium   44.7222     5.6213   7.956 6.88e-06 ***\n#&gt; subscriptionPremium+  18.0722     2.1659   8.344 4.37e-06 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 2.958 on 11 degrees of freedom\n#&gt; Multiple R-squared:  0.9597, Adjusted R-squared:  0.9487 \n#&gt; F-statistic: 87.21 on 3 and 11 DF,  p-value: 5.956e-08\n\n\n\nModel 1: Coefficients: Intercept: 78.8860 Follow-ups: -3.3093 Interpretation: The intercept (78.8860) represents the estimated satisfaction when the number of follow-up calls is zero. The coefficient for follow-ups (-3.3093) suggests that, on average, for each additional follow-up call, satisfaction decreases by approximately 3.31 units. Statistical Significance: Both intercept and follow-ups have p-values less than 0.05, indicating statistical significance. Model Fit: R²=0.658: Approximately 65.8% of the variability in satisfaction is explained by the number of follow-up calls.  Model 2: Coefficients: Intercept: 26.7667 Follow-ups: 2.1944 Subscription Premium: 44.7222 Subscription Premium+: 18.0722 Interpretation: The intercept (26.7667) represents the estimated satisfaction when follow-up calls and all subscription variables are zero. The coefficient for follow-ups (2.1944) suggests that, on average, for each additional follow-up call, satisfaction increases by approximately 2.19 units. The coefficients for subscription levels indicate the change in satisfaction compared to the baseline (assumed to be subscription Starter). Statistical Significance: All coefficients have p-values less than 0.05, indicating statistical significance. Model Fit: R² = 0.9597 : Approximately 95.97% of the variability in satisfaction is explained by follow-up calls and subscription levels.  Model 2 provides a more comprehensive understanding of the factors influencing satisfaction as it includes both follow-up calls and subscription levels. In Model 2, the positive coefficient for follow-ups suggests that more follow-up calls are associated with higher satisfaction. The subscription coefficients in Model 2 indicate that, compared to the baseline (Starter), both Premium and Premium+ subscriptions are associated with higher satisfaction. Overall, Model 2 suggests that, when accounting for subscription levels, both follow-up calls and subscription levels significantly contribute to explaining satisfaction. The high R² value in Model 2 indicates that the combination of follow-up calls and subscription levels explains a large portion of the variability in satisfaction\n\n\n#4\n# Assuming 'follow_ups', 'satisfaction', and 'subscription' are column names in dataset\nlibrary(dagitty)\nlibrary(ggdag)\n\n# Create a DAG model manually\ndag_model &lt;- dagitty('dag {\n  follow_ups [exposure,pos=\"1,1\"]\n  satisfaction [outcome,pos=\"2,1\"]\n  subscription [pos=\"3,1\"]\n\n  subscription -&gt; satisfaction\n  follow_ups -&gt; satisfaction\n}')\n\n# plot adjustment sets\nggdag_adjustment_set(dag_model, shadow = T) +\n  theme_minimal() + # custom theme, can be left out\n  geom_dag_edges(edge_color = \"white\")"
  },
  {
    "objectID": "content/01_journal/07_matching.html",
    "href": "content/01_journal/07_matching.html",
    "title": "Matching and Subclassification",
    "section": "",
    "text": "data &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/membership.rds\")\n\n# Install and load the 'dagitty' package\nlibrary(dagitty)\n\n# Create a DAG\ndag &lt;- dagitty(\"dag {\n  age -&gt; avg_purch\n  sex -&gt; avg_purch\n  pre_avg_purch -&gt; avg_purch\n  card -&gt; avg_purch\n}\")\n\n# Plot the DAG\nplot(dag)\n\n#&gt; Plot coordinates for graph not supplied! Generating coordinates, see ?coordinates for how to set your own.\n\n\n\n\n\n\n\n\n\n\n#2\n\n# Calculate average purchase for customers with plus membership\navg_purchase_treatment &lt;- mean(data$avg_purch[data$card == 1], na.rm = TRUE)\n\n# Calculate average purchase for customers without plus membership\navg_purchase_control &lt;- mean(data$avg_purch[data$card == 0], na.rm = TRUE)\n\n# Compute the naive estimate of the average treatment effect\nnaive_ate &lt;- avg_purchase_treatment - avg_purchase_control\n\n# Print or use the naive_ate value\ncat(\"Naive Estimate of ATE:\", naive_ate, \"\\n\")\n\n#&gt; Naive Estimate of ATE: 25.2195\n\n\n\n#3.1\n\n# Install and load the 'MatchIt' package if not already installed\nif (!requireNamespace(\"MatchIt\", quietly = TRUE)) {\n  install.packages(\"MatchIt\")\n}\nlibrary(MatchIt)\n\n# Create a data frame with the treatment variable ('card') and the covariates\nmatch_data &lt;- data.frame(card = data$card, age = data$age, sex = data$sex, pre_avg_purch = data$pre_avg_purch, avg_purch = data$avg_purch)\n\n# Perform Coarsened Exact Matching with MatchIt\ncem_result &lt;- matchit(card ~ age + sex + pre_avg_purch + avg_purch, data = match_data, method = \"cem\")\n\n# Print summary\nsummary(cem_result)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + sex + pre_avg_purch + avg_purch, \n#&gt;     data = match_data, method = \"cem\")\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 42.0331       39.1574          0.2064     1.1524    0.0438\n#&gt; sex                  0.5087        0.5002          0.0171          .    0.0086\n#&gt; pre_avg_purch       76.3938       66.0438          0.3936     1.0276    0.1092\n#&gt; avg_purch           91.1592       65.9397          0.8239     1.0590    0.2225\n#&gt;               eCDF Max\n#&gt; age             0.0864\n#&gt; sex             0.0086\n#&gt; pre_avg_purch   0.1545\n#&gt; avg_purch       0.3281\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 40.9009       40.8982          0.0002     0.9970    0.0024\n#&gt; sex                  0.5119        0.5119          0.0000          .    0.0000\n#&gt; pre_avg_purch       73.6419       73.9904         -0.0133     0.9954    0.0043\n#&gt; avg_purch           85.9194       84.9341          0.0322     1.0022    0.0098\n#&gt;               eCDF Max Std. Pair Dist.\n#&gt; age             0.0134          0.1189\n#&gt; sex             0.0000          0.0000\n#&gt; pre_avg_purch   0.0136          0.1522\n#&gt; avg_purch       0.0300          0.1595\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All           5768.      4232\n#&gt; Matched (ESS) 2005.91    3622\n#&gt; Matched       4895.      3622\n#&gt; Unmatched      873.       610\n#&gt; Discarded        0.         0\n\ntreated_outcome &lt;- match_data$avg_purch[match_data$card == 1]\ncontrol_outcome &lt;- match_data$avg_purch[match_data$card == 0]\n\n# Calculate ATE\nate &lt;- mean(treated_outcome) - mean(control_outcome)\n\n# Print or return the exact estimate of ATE\ncat(\"(Coarsened) Exact Matching Estimate of ATE:\", ate, \"\\n\")\n\n#&gt; (Coarsened) Exact Matching Estimate of ATE: 25.2195\n\n\n\n#3.2\n\n# Assuming 'data' is your dataset\nlibrary(MatchIt)\nnn_matchit &lt;- matchit(card ~ age + sex + pre_avg_purch + avg_purch,\n                      data = data,\n                      method = \"nearest\",\n                      distance = \"mahalanobis\",\n                      replace = TRUE)\n\n\n\nsummary(nn_matchit)\n\n#&gt; \n#&gt; Call:\n#&gt; matchit(formula = card ~ age + sex + pre_avg_purch + avg_purch, \n#&gt;     data = data, method = \"nearest\", distance = \"mahalanobis\", \n#&gt;     replace = TRUE)\n#&gt; \n#&gt; Summary of Balance for All Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 42.0331       39.1574          0.2064     1.1524    0.0438\n#&gt; sex                  0.5087        0.5002          0.0171          .    0.0086\n#&gt; pre_avg_purch       76.3938       66.0438          0.3936     1.0276    0.1092\n#&gt; avg_purch           91.1592       65.9397          0.8239     1.0590    0.2225\n#&gt;               eCDF Max\n#&gt; age             0.0864\n#&gt; sex             0.0086\n#&gt; pre_avg_purch   0.1545\n#&gt; avg_purch       0.3281\n#&gt; \n#&gt; Summary of Balance for Matched Data:\n#&gt;               Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\n#&gt; age                 42.0331       41.9080          0.0090     1.0426    0.0039\n#&gt; sex                  0.5087        0.5087          0.0000          .    0.0000\n#&gt; pre_avg_purch       76.3938       76.0192          0.0142     1.0607    0.0035\n#&gt; avg_purch           91.1592       90.2268          0.0305     1.0790    0.0051\n#&gt;               eCDF Max Std. Pair Dist.\n#&gt; age             0.0121          0.1025\n#&gt; sex             0.0000          0.0000\n#&gt; pre_avg_purch   0.0187          0.1094\n#&gt; avg_purch       0.0208          0.1117\n#&gt; \n#&gt; Sample Sizes:\n#&gt;               Control Treated\n#&gt; All           5768.      4232\n#&gt; Matched (ESS) 1278.54    4232\n#&gt; Matched       2204.      4232\n#&gt; Unmatched     3564.         0\n#&gt; Discarded        0.         0\n\n# Use matched data\ndata_nn &lt;- match.data(nn_matchit)\n\n# Estimation using linear regression\nmodel_nn &lt;- lm(avg_purch ~ card, data = data_nn)\n\n# Display summary of the regression model\nsummary(model_nn)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = data_nn)\n#&gt; \n#&gt; Residuals:\n#&gt;      Min       1Q   Median       3Q      Max \n#&gt; -101.515  -20.381    0.218   20.392  106.246 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  79.8593     0.6348  125.79   &lt;2e-16 ***\n#&gt; card         11.2999     0.7829   14.43   &lt;2e-16 ***\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 29.8 on 6434 degrees of freedom\n#&gt; Multiple R-squared:  0.03136,    Adjusted R-squared:  0.03121 \n#&gt; F-statistic: 208.3 on 1 and 6434 DF,  p-value: &lt; 2.2e-16\n\n\n\n#3.3\n\nlibrary(Matching)\n\nlibrary(dplyr)\n\n# Assuming 'data' is your dataset\npropensity_model &lt;- glm(card ~ age + sex + pre_avg_purch + avg_purch, \n                         data = data, \n                         family = \"binomial\"(link = \"logit\"))\n# Add propensities to table\ndata_ipw &lt;- data %&gt;% mutate(propensity = predict(propensity_model, type = \"response\"))\n\n# Extend data by IPW scores\ndata_ipw &lt;- data_ipw %&gt;% mutate(\n  ipw = (card / propensity) + ((1 - card) / (1 - propensity))\n)\n\n# Look at data with IPW scores\ndata_ipw %&gt;% \n  select(card, age, sex, pre_avg_purch, avg_purch, propensity, ipw)\n\n\n\n  \n\n\n# (2) Estimation\nipw_model &lt;- lm(avg_purch ~ card, data = data_ipw, weights = ipw)\nsummary(ipw_model)\n\n#&gt; \n#&gt; Call:\n#&gt; lm(formula = avg_purch ~ card, data = data_ipw, weights = ipw)\n#&gt; \n#&gt; Weighted Residuals:\n#&gt;     Min      1Q  Median      3Q     Max \n#&gt; -525.64  -28.55   -0.11   30.04  441.02 \n#&gt; \n#&gt; Coefficients:\n#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    \n#&gt; (Intercept)  76.5744     0.4664 164.189   &lt;2e-16 ***\n#&gt; card         -0.6361     0.6577  -0.967    0.333    \n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt; \n#&gt; Residual standard error: 46.6 on 9998 degrees of freedom\n#&gt; Multiple R-squared:  9.356e-05,  Adjusted R-squared:  -6.45e-06 \n#&gt; F-statistic: 0.9355 on 1 and 9998 DF,  p-value: 0.3335"
  },
  {
    "objectID": "content/01_journal/09_iv.html",
    "href": "content/01_journal/09_iv.html",
    "title": "Instrumental Variables",
    "section": "",
    "text": "#1\ndata &lt;- readRDS(\"C:/Users/Anjali/Downloads/Causal_Data_Science_Data (1)/Causal_Data_Science_Data/rand_enc.rds\")\n\n#library(dagitty)\n\n# Define the DAG\n#dag &lt;- dagitty('\n#  dag {\n#    rand_enc [pos=\"0,0\"]\n#    used_ftr [pos=\"1,0\"]\n#    time_spent [pos=\"2,0\"]\n #   \n  #  # Edges\n   # rand_enc -&gt; used_ftr\n    #rand_enc -&gt; time_spent\n    #used_ftr -&gt; time_spent\n  #}\n#')\n\n\n#plot(dag)\n\n\n#2\n\nnaive_estimate &lt;- tapply(data$time_spent, data$rand_enc, mean)\n\n# Print the results\ncat(\"Naive Estimate for Encouraged Users:\", naive_estimate[2], \"\\n\")\n\n#&gt; Naive Estimate for Encouraged Users: 24.25068\n\ncat(\"Naive Estimate for Not Encouraged Users:\", naive_estimate[1], \"\\n\")\n\n#&gt; Naive Estimate for Not Encouraged Users: 22.29389\n\n# Assuming your data frame is named 'df'\nmodel &lt;- lm(time_spent ~ rand_enc + used_ftr, data = data)\n\n# Extract coefficients\ncoefficients &lt;- coef(model)\n\n# Print the results\ncat(\"Biased Estimate for Encouraged Users:\", coefficients[\"rand_enc\"], \"\\n\")\n\n#&gt; Biased Estimate for Encouraged Users: -0.2274239\n\n\n\n#3\n\ncorrelation_instrument1_endogenous &lt;- cor(data$rand_enc, data$time_spent)\ncorrelation_instrument2_endogenous &lt;- cor(data$used_ftr, data$time_spent)\n\nmodel_endogenous &lt;- lm(time_spent ~ rand_enc + used_ftr, data = data)\nresiduals &lt;- residuals(model_endogenous)\n\ncorrelation_instrument1_residuals &lt;- cor(data$rand_enc, residuals)\ncorrelation_instrument2_residuals &lt;- cor(data$used_ftr, residuals)\n\ncorrelation_endogenous_dependent &lt;- cor(data$time_spent, data$time_spent)\n\n# Print the results\ncat(\"Correlation between instrument1 and endogenous variable:\", correlation_instrument1_endogenous, \"\\n\")\n\n#&gt; Correlation between instrument1 and endogenous variable: 0.1296716\n\ncat(\"Correlation between instrument2 and endogenous variable:\", correlation_instrument2_endogenous, \"\\n\")\n\n#&gt; Correlation between instrument2 and endogenous variable: 0.7050147\n\ncat(\"Correlation between instrument1 and residuals:\", correlation_instrument1_residuals, \"\\n\")\n\n#&gt; Correlation between instrument1 and residuals: -1.207024e-16\n\ncat(\"Correlation between instrument2 and residuals:\", correlation_instrument2_residuals, \"\\n\")\n\n#&gt; Correlation between instrument2 and residuals: 9.569848e-17\n\ncat(\"Correlation between endogenous variable and dependent variable:\", correlation_endogenous_dependent, \"\\n\")\n\n#&gt; Correlation between endogenous variable and dependent variable: 1\n\n\n\n#4\n\n# Load the ivreg library\nlibrary(ivreg)\n\n# IV estimate using 2SLS\niv_model &lt;- ivreg(time_spent ~ used_ftr | rand_enc, data = data)\niv_estimate &lt;- coef(iv_model)[\"used_ftr\"]\n\n# Print the results\ncat(\"IV Estimate (2SLS):\", iv_estimate, \"\\n\")\n\n#&gt; IV Estimate (2SLS): 9.738175"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Lab Journal",
    "section": "",
    "text": "This is a template example for lab journaling. Students in the data science courses at the Institute of Entrepreneurship will use this template to learn R for business analytics. Students can replace this text as they wish."
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "My Lab Journal",
    "section": "How to use",
    "text": "How to use\n\nAccept the assignment and get your own github repo.\nBlog/journal what you are doing in R, by editing the .qmd files.\nSee the links page for lots of helpful links on learning R.\nChange everything to make it your own.\nMake sure to render you website every time before you want to upload changes."
  }
]